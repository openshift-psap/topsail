---
- name: Ensure that the secret properties file exists
  stat:
    path: "{{ notebooks_ods_ci_scale_test_secret_properties_file }}"

- name: Ensure that the user count is set
  fail: msg="user count isn't set"
  when: notebooks_ods_ci_scale_test_user_count | int < 0

- name: Ensure that the IDP name is set
  fail: msg="idp name isn't set"
  when: not notebooks_ods_ci_scale_test_idp_name

- name: Ensure that the username prefix is set
  fail: msg="username prefix isn't set"
  when: not notebooks_ods_ci_scale_test_username_prefix

- name: Define the test namespace
  set_fact:
    tester_namespace: "{{ notebooks_ods_ci_scale_test_namespace }}"

- name: Update the Exclude tags if necessary
  set_fact:
    notebooks_ods_ci_scale_test_ods_ci_exclude_tags: "{% if notebooks_ods_ci_scale_test_only_create_notebooks | bool %}JupyterLabORWait{% else %}{{ notebooks_ods_ci_scale_test_ods_ci_exclude_tags }}{% endif %}"

- name: Define the test environments
  set_fact:
    rhods_ods_ci_image: image-registry.openshift-image-registry.svc:5000/{{ tester_namespace }}/{{ notebooks_ods_ci_scale_test_ods_ci_istag }}
    rhods_artifacts_exporter_image: image-registry.openshift-image-registry.svc:5000/{{ tester_namespace }}/{{ notebooks_ods_ci_scale_test_artifacts_exporter_istag }}
    rhods_notebook_namespace: rhods-notebooks
    tester_job_name: ods-ci
    test_artifacts_collected: "{{ notebooks_ods_ci_scale_test_artifacts_collected }}"
    capture_prom_db: "{{ notebooks_ods_ci_scale_test_capture_prom_db }}"

- name: Set system-under-test == driver-cluster if no system-under-test (SUT) is provided
  set_fact:
    sut_cluster_kubeconfig: "{{ notebooks_ods_ci_scale_test_sut_cluster_kubeconfig | default(lookup('env', 'KUBECONFIG'), true) }}"

- name: Fetch the notebook file (to validate the URL and store it)
  when: 'not ".svc/" in notebooks_ods_ci_scale_test_notebook_url'
  get_url:
    url: "{{ notebooks_ods_ci_scale_test_notebook_url }}"
    dest: "{{ artifact_extra_logs_dir }}/notebook.raw"
    mode: '0440'

- name: Fetch RHODS endpoints from the SUT cluster
  environment:
    KUBECONFIG: '{{ sut_cluster_kubeconfig }}'
  block:
  - name: Test the connectivity of the SUT cluster
    command: oc whoami --show-console

  - name: Get RHODS dashboard address (SUT cluster)
    command: oc get route/rhods-dashboard -n redhat-ods-applications -ojsonpath={.spec.host}
    register: rhods_dashboard_hostname_cmd

  - name: Get OCP console URL (SUT cluster)
    command: oc whoami --show-console
    register: oc_console_url_cmd

  - name: Get OCP API URL (SUT cluster)
    command: oc whoami --show-server
    register: oc_api_url_cmd

  - name: Get the RHODS CSV name
    shell:
      set -o pipefail;
      oc get csv -oname -n redhat-ods-operator | grep rhods-operator
    register: rhods_csv_cmd

  - name: Get the RHODS version
    shell:
      set -o pipefail;
      oc get {{ rhods_csv_cmd.stdout }} -n redhat-ods-operator -oname | grep rhods-operator | cut -d/ -f2 | cut -d. -f2-
    register: rhods_version_cmd

  - name: Get the Dashboard Product name (to distinguish RHODS from ODH). Currently hardcoded to RHODS.
    # We'll have to find another way to distinguish RHODS from ODH, this doesn't work anymore:
    # oc -c rhods-dashboard -n redhat-ods-applications -n redhat-ods-applications rsh deploy/rhods-dashboard bash -c "echo ${ODH_PRODUCT_NAME:-Open Data Hub}"
    command:
      echo "Red Hat OpenShift AI"
    register: rhods_dashboard_product_name

  - name: Get the image name description
    command:
      oc get imagestream "{{ notebooks_ods_ci_scale_test_notebook_image_name }}"
         -n redhat-ods-applications
         -ojsonpath='{.metadata.annotations.opendatahub\.io/notebook-image-name}'
    register: notebook_image_name_descr_cmd

  - name: Save the computed variables
    set_fact:
      rhods_dashboard_product_name: "{{ rhods_dashboard_product_name.stdout }}"
      notebook_image_name_descr: "{{ notebook_image_name_descr_cmd.stdout }}"

- name: Terminate the notebooks
  environment:
    KUBECONFIG: '{{ sut_cluster_kubeconfig }}'
  shell:
    set -o pipefail;
    oc get notebooks -A -ojsonpath='{range .items[*]}{.metadata.name}{" -n "}{.metadata.namespace}{"\n"}{end}' |
      xargs --no-run-if-empty --replace
            bash -c "oc annotate notebook/{} --overwrite
                 kubeflow-resource-stopped=stopped-by-topsail
                 -oname" > /dev/null
  when: notebooks_ods_ci_scale_test_stop_notebooks_on_exit

- name: Get the ODS-CI sample var file
  shell:
    oc debug istag/{{ notebooks_ods_ci_scale_test_ods_ci_istag }}
       -n {{ tester_namespace }}
       -- cat test-variables.yml > /tmp/test-variables.yml.example

- name: Apply the ODS-CI template
  shell: |
    set -o pipefail;
    set -e;

    OCP_CONSOLE_URL="{{ oc_console_url_cmd.stdout }}";
    OCP_API_URL="{{ oc_api_url_cmd.stdout }}";
    ODH_DASHBOARD_URL="https://{{ rhods_dashboard_hostname_cmd.stdout }}";

    TEST_USER_AUTH_TYPE="{{ notebooks_ods_ci_scale_test_idp_name }}";
    TEST_USER_USERNAME="{{ notebooks_ods_ci_scale_test_username_prefix }}#{USER_INDEX}";

    export TEST_USER_PASSWORD="PASSWORD_WILL_BE_HERE";

    RHODS_VERSION="{{ rhods_version_cmd.stdout }}";

    TEST_VAR_SAFE={{ artifact_extra_logs_dir }}/test-variables_safe.yml
    TEST_VAR_FULL=/tmp/test-variables.yml

    cat /tmp/test-variables.yml.example | \
      yq -y .OCP_CONSOLE_URL=\"${OCP_CONSOLE_URL}\" | \
      yq -y .OCP_API_URL=\"${OCP_API_URL}\" | \
      yq -y .ODH_DASHBOARD_URL=\"${ODH_DASHBOARD_URL}\" | \
      yq -y .RHODS_VERSION=\"${RHODS_VERSION}\" | \
      yq -y .TEST_USER.AUTH_TYPE=\"${TEST_USER_AUTH_TYPE}\" | \
      yq -y .TEST_USER.USERNAME=\"${TEST_USER_USERNAME}\" \
        > "$TEST_VAR_SAFE"

    cp "$TEST_VAR_SAFE" "$TEST_VAR_FULL"

    TEST_USER_PASSWORD="$(cat "{{ notebooks_ods_ci_scale_test_secret_properties_file }}" | grep '^user_password=' | cut -d= -f2)";

    yq -yi .TEST_USER.PASSWORD=\"${TEST_USER_PASSWORD}\" "$TEST_VAR_FULL"

- name: Delete the ODS-CI secret, it it exists
  command:
    oc delete secret ods-ci-test-variables
       -n {{ tester_namespace }}
       --ignore-not-found

- name: Create the ODS-CI secret
  command:
    oc create secret generic ods-ci-test-variables
       --from-file test-variables.yml=/tmp/test-variables.yml
       -n {{ tester_namespace }}

- name: Delete the ODS-CI secret file
  file:
    path: /tmp/test-variables.yml
    state: absent

- name: Create the src artifacts directory
  file:
    path: "{{ artifact_extra_logs_dir }}/src/"
    state: directory
    mode: '0755'

- name: Instantiate the RHODS tester job template
  template:
    src: "{{ notebooks_ods_ci_scale_test_job }}"
    dest: "{{ artifact_extra_logs_dir }}/src/000_notebooks_ods_ci_scale_test.yaml"
    mode: '0400'

- name: Delete the RHODS test entrypoint, if it exists
  command:
    oc delete cm/rhods-notebook-ux-e2e-scale-test-entrypoint
       -n {{ tester_namespace }}
       --ignore-not-found

- name: Create the RHODS test entrypoint
  command:
    oc create cm rhods-notebook-ux-e2e-scale-test-entrypoint
       "--from-file=entrypoint.sh={{ notebooks_ods_ci_scale_test_entrypoint }}"
       "--from-file=state-signal_barrier.py={{ notebooks_ods_ci_scale_test_state_signal_barrier }}"
       "--from-file=artifacts-exporter.sh={{ notebooks_ods_ci_scale_test_s3_artifacts_exporter_sidecar }}"
       "--from-file={{ notebooks_ods_ci_scale_test_test_case_directory }}"
       -n {{ tester_namespace }}

- name: Empty the Minio S3 bucket
  shell: |
    oc -c mc -n {{ notebooks_ods_ci_scale_test_minio_namespace }} rsh $(oc get pod -lapp=minio -n {{ notebooks_ods_ci_scale_test_minio_namespace }} -oname) \
       mc --config-dir /tmp rm minio/{{ notebooks_ods_ci_scale_test_minio_bucket_name }}/ --recursive --force --quiet >/dev/null;
    oc -c mc -n {{ notebooks_ods_ci_scale_test_minio_namespace }} rsh $(oc get pod -lapp=minio -n {{ notebooks_ods_ci_scale_test_minio_namespace }} -oname) \
       rm -rf /artifacts/to_export > /dev/null
    oc -c mc -n {{ notebooks_ods_ci_scale_test_minio_namespace }} rsh $(oc get pod -lapp=minio -n {{ notebooks_ods_ci_scale_test_minio_namespace }} -oname) \
       mc --config-dir /tmp cp /etc/os-release minio/{{ notebooks_ods_ci_scale_test_minio_bucket_name }}; # without it, cp may fail if the bucket is empty
  failed_when: false

- name: Delete the RHODS tester job, if it exists
  command:
    oc delete
       -f "{{ artifact_extra_logs_dir }}/src/000_notebooks_ods_ci_scale_test.yaml"
       --ignore-not-found
       -n {{ tester_namespace }}

# ---

- name: Cleanup the Prometheus databases of the sutest cluster
  when: capture_prom_db | bool
  environment:
    KUBECONFIG: '{{ sut_cluster_kubeconfig }}'
  block:
  - name: Cleanup the RHODS Prometheus database of the sutest cluster
    include_role:
      name: cluster_prometheus_db
    vars:
      cluster_prometheus_db_mode: reset
      cluster_prometheus_db_label: deployment=prometheus
      cluster_prometheus_db_namespace: redhat-ods-monitoring

  - name: Cleanup the Prometheus database of the sutest cluster
    include_role:
      name: cluster_prometheus_db
    vars:
      cluster_prometheus_db_mode: reset

- name: Cleanup the Prometheus database of the driver cluster
  when: capture_prom_db | bool
  include_role:
    name: cluster_prometheus_db
  vars:
    cluster_prometheus_db_mode: reset

# ---

- name: Create the RHODS test job
  shell:
    set -o pipefail;
    cat "{{ artifact_extra_logs_dir }}/src/000_notebooks_ods_ci_scale_test.yaml"
      | sed 's/$JOB_CREATION_TIME/'$(date "+%Y-%m-%dT%H:%M:%SZ" --utc)'/'
      | oc create -f- -n "{{ tester_namespace }}"

- name: Wait for the RHODS tester job to start
  shell:
    oc get jobs/ods-ci -ojsonpath={.status.startTime} -n {{ tester_namespace }}
  register: wait_rhods_test_job_start
  retries: 12
  delay: 5
  until: wait_rhods_test_job_start.stdout

- name: Wait for the RHODS tester job to terminate
  command:
    oc get jobs/ods-ci -ojsonpath={.status.active} -n {{ tester_namespace }}
  register: wait_rhods_test_job
  retries: 180
  delay: 60
  until: not wait_rhods_test_job.stdout
  failed_when: false

- name: Test if the Notebook Pods did not crash (reboot)
  shell:
    set -o pipefail;
    oc get pods -lopendatahub.io/dashboard=true -A -ojsonpath='{range .items[*]}{range .status.containerStatuses[*]}{.restartCount}{"\n"}{end}{end}'
       | tr ' ' '\n'
       | python -c "import sys; print(sum(int(l) for l in sys.stdin))"
  register: check_pod_restart_count_cmd
  failed_when: false

- name: Capture the sutest cluster artifacts
  include_tasks: artifacts_sutest.yml

- name: Capture the information about the notebook projects
  include_tasks: artifacts_sutest_project.yml

- name: Capture the driver cluster artifacts
  include_tasks: artifacts_driver.yml

- name: Capture the rest of the artifacts
  include_tasks: artifacts.yml

- name: Show the artifacts directory
  debug: msg="The test artifacts have been stored in {{ artifact_extra_logs_dir }}"

- name: Test if the RHODS test job crashed
  command:
    oc get jobs/ods-ci -ojsonpath={.status.failed} -n {{ tester_namespace }}
  register: check_rhods_test_job
  failed_when: check_rhods_test_job.stdout | length > 0

- name: Count how many jobs succeeded, fail in none succeeded
  shell:
    set -o pipefail;
    (cat "{{ artifact_extra_logs_dir }}"/ods-ci/ods-ci-*/test.exit_code || true)
      | (grep '^0$' || true)
      | wc -l
  register: success_count_cmd
  failed_when: success_count_cmd.stdout == "0"

- name: Fail if the notebooks Pods had to restart
  when: check_pod_restart_count_cmd.stdout != "0"
  fail: msg="{{ check_pod_restart_count_cmd.stdout }} notebook Pods had to restart"
