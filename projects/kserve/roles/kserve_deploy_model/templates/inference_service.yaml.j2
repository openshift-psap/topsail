apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  annotations:
    serving.knative.openshift.io/enablePassthrough: "true"
    sidecar.istio.io/inject: "true"
    sidecar.istio.io/rewriteAppHTTPProbers: "true"
    serving.kserve.io/enable-prometheus-scraping: "true"
    serving.kserve.io/deploymentMode: "{% if kserve_deploy_model_raw_deployment %}RawDeployment{% else %}Serverless{% endif %}"
  labels:
    opendatahub.io/dashboard: "true"
    protocol: "grpconly" # workaround for https://issues.redhat.com/browse/RHOAIENG-165
  name: {{ kserve_deploy_model_inference_service_name }}
  namespace: {{ kserve_deploy_model_namespace }}
spec:
  predictor:
{% if kserve_deploy_model_inference_service_min_replicas is not none %}
    minReplicas: {{ kserve_deploy_model_inference_service_min_replicas }}
{% endif %}
    serviceAccountName: {{ kserve_deploy_model_sa_name }}
    model:
      modelFormat:
        name: {{ kserve_deploy_model_inference_service_model_format }}
      runtime: {{ kserve_deploy_model_sr_name }}
      storageUri: {{ kserve_deploy_model_storage_uri }}
