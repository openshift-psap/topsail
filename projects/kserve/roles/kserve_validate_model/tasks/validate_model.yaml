---
- name: Ensure that GRPCurl is available
  shell:
    which grpcurl

- name: Create the artifact directory
  file:
    path: "{{ artifact_extra_logs_dir }}/{{ kserve_validate_model_inference_service_name }}"
    state: directory
    mode: '0755'

- name: Get the name of the model endpoint
  shell: |
    set -o pipefail;
    {% if kserve_validate_model_raw_deployment %}
    if test -e /run/secrets/kubernetes.io/serviceaccount/namespace; then
      # inside the cluster
      svc_name=$(oc get svc \
                      -lserving.kserve.io/inferenceservice={{ kserve_validate_model_inference_service_name }} \
                      -ojsonpath={.items[0].metadata.name} \
                      -n {{ kserve_validate_model_namespace }});

      echo "${svc_name}.{{ kserve_validate_model_namespace }}.svc.cluster.local:8033"
    else
      # outside the cluster
      # port-forwaring enabled in the next task
      echo "localhost:8080"
    fi
    {% else %}
    oc get ksvc \
       -lserving.kserve.io/inferenceservice={{ kserve_validate_model_inference_service_name }} \
       -n {{ kserve_validate_model_namespace }} \
       -ojsonpath='{.items[0].status.url}' \
       | sed 's|https://||' \
       | sed 's/$/:443/'
    {% endif %}
  register: model_endpoint_cmd

- name: Wait for the model to answer successfully
  shell: |
    set -o pipefail;
    set -e;

    {% if kserve_validate_model_raw_deployment %}
    if ! test -e /run/secrets/kubernetes.io/serviceaccount/namespace; then
      oc port-forward svc/{{ kserve_validate_model_inference_service_name }}-predictor 8080:8033 -n {{ kserve_validate_model_namespace }} &
      oc_pid=$!
      trap "kill -9 $oc_pid" SIGINT SIGTERM EXIT

      # I cannot find any better at the moment :/
      # curl localhost:8080 could do the job ... but it leads to a 'read: connection reset by peer' :|
      sleep 5;
    fi
    {% endif %}

    dest="{{ artifact_extra_logs_dir }}/{{ kserve_validate_model_inference_service_name }}/answers.json"
    query="{{ artifact_extra_logs_dir }}/{{ kserve_validate_model_inference_service_name }}/questions.json"

    {% if kserve_validate_model_sr_container_flavor == "tgis" %}
    GRPCURL_DATA='{
        "requests": [ {
                "text": "At what temperature does Nitrogen boil?"

        } ],
        "params": {
            "stopping": {
                "min_new_tokens": 10,
                "max_new_tokens": 100
            }
        }
    }'
    {% else %}
    GRPCURL_DATA='{"text": "At what temperature does liquid Nitrogen boil?"}'
    {% endif %}

    echo $GRPCURL_DATA >> "$query"
    for i in {1..{{ kserve_validate_model_query_count }}}; do
      grpcurl \
        {% if kserve_validate_model_proto %} -proto {{ kserve_validate_model_proto }} {% endif %} \
        {% if kserve_validate_model_raw_deployment %} -plaintext {% else %} -insecure {% endif %} \
        -d "$GRPCURL_DATA" \
        -H "mm-model-id: {{ kserve_validate_model_model_id }}" \
        {{ model_endpoint_cmd.stdout }} \
        {{ kserve_validate_model_method }} >> "$dest"
       echo "Call $i/{{ kserve_validate_model_query_count }} passed"
    done
  register: grpcurl_working_cmd
  retries: 5
  delay: 30
  until: grpcurl_working_cmd.rc == 0
