serving_runtime:
  container_flavor: tgis
  kserve:
    resource_request:
      cpu: 8
      memory: 40 # in Gi
    extra_env:
      TRANSFORMERS_CACHE: "/tmp/transformers_cache"
      MAX_BATCH_SIZE: 96
      MAX_CONCURRENT_REQUESTS: 128
      MAX_NEW_TOKENS: 4096
  transformer:
    resource_request:
      cpu: 0
      memory: 0
    extra_env: {}
inference_service:
  model_format: "pytorch"
  min_replicas: 1
testing:
  size: small
  max_concurrency: 32
