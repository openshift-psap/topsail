ci_presets:
  # name of the presets to apply, or null if no preset
  name: null
  # list of names of the presets to apply, or a single name, or null if no preset
  names: null

  single:
    clusters.create.type: single

  keep:
    extends: [spot_cluster]

    clusters.create.keep: true
    clusters.create.ocp.tags.Project: PSAP/Watsonx/serving/scale/home-dev
    clusters.create.ocp.tags.TicketId: 229

  light_cluster:
    clusters.create.ocp.deploy_cluster.target: cluster_light

  light:
    extends: [light_cluster]

  quick:
    extends: [no_gpu]
    kserve.model.directory_prefix: caikit_tgis
    tests.e2e.models:
    - flan-t5-small-cpu
    - flan-t5-small-cpu

  no_gpu:
    gpu.prepare_cluster: false
    clusters.sutest.compute.machineset.type: m6i.2xlarge

  gpu:
    gpu.prepare_cluster: true

  cluster_dgx:
    clusters.sutest.compute.machineset.type: "DGX A100-40GB"

  cluster_icelake:
    clusters.sutest.compute.machineset.type: "Icelake"

  cluster_a30:
    clusters.sutest.compute.machineset.type: "PSAP A30 node"

  metal:
    clusters.sutest.is_metal: true
    clusters.driver.is_metal: true
    clusters.sutest.compute.dedicated: false
    clusters.driver.compute.dedicated: false
    clusters.sutest.compute.machineset.type: "bare-metal node"

  not_metal:
    clusters.sutest.is_metal: false
    clusters.driver.is_metal: false

  spot_compute:
    clusters.sutest.compute.machineset.spot: true
    clusters.driver.compute.machineset.spot: true

  spot_cluster:
    extends: [spot_compute]
    clusters.create.ocp.workers.spot: true
    clusters.create.ocp.region: us-east-2

  cleanup:
    clusters.cleanup_on_exit: true

  # ---

  e2e_perf_strict_limits:
    extends: [e2e_perf]
    tests.e2e.limits_equals_requests: true

  e2e_perf:
    extends: [e2e_gpu]
    tests.e2e.mode: single
    tests.e2e.limits_equals_requests: false
    matbench.workload: projects.kserve.visualizations.kserve-llm
    gpu.time_sharing.replicas: 1
    clusters.sutest.compute.machineset.count: 1

  e2e:
    tests.mode: e2e
    gpu.time_sharing.replicas: 1

  e2e_multi:
    extends: [e2e_gpu]
    tests.e2e.mode: multi
    gpu.time_sharing.replicas: 1
    matbench.lts.generate: false

  e2e_gpu:
    extends: [e2e]
    gpu.prepare_cluster: true
    clusters.sutest.compute.machineset.spot: false
    clusters.sutest.compute.machineset.type: g4dn.2xlarge

  e2e_all_models:
    tests.e2e.models:
    - flan-t5-small-cpu
    - flan-t5-small-gpu
    - flan-t5-large-gpu
    - bloom-560m
    - mpt-7b-instruct2

  raw:
    kserve.raw_deployment.enabled: true

  tgis:
    kserve.inference_service.validation.method: fmaas.GenerationService/Generate
    kserve.inference_service.validation.proto: projects/kserve/testing/protos/tgis_generation.proto
    tests.e2e.llm_load_test.args.plugin: tgis_grpc_plugin

  quick_raw:
    extends: [raw, no_gpu, tgis]

    tests.e2e.models: [flan-t5-small-hf-cpu, flan-t5-small-hf-cpu]
    tests.e2e.llm_load_test.args.concurrency: 2

  single_raw:
    extends: [quick_raw]
    tests.e2e.models: [flan-t5-small-hf-cpu]

  # ---

  3min:
    tests.e2e.llm_load_test.args.duration: 180

  5min:
    tests.e2e.llm_load_test.args.duration: 300

  10min:
    tests.e2e.llm_load_test.args.duration: 600

  # ---

  scale_test:
    tests.mode: scale
    matbench.workload: projects.kserve.visualizations.kserve-scale
    tests.prom_plot_workload: null
    kserve.model.serving_runtime.mute_logs: false

  scale_gpu:
    extends: [scale_test]
    gpu.prepare_cluster: true
    clusters.sutest.compute.machineset.spot: false
    clusters.sutest.compute.machineset.type: g4dn.2xlarge
    tests.scale.model.name: caikit_tgis/flan-t5-small-gpu
    gpu.time_sharing.replicas: 17

  # ---

  customize_smcp:
    kserve.customize.serverless.enabled: true
    kserve.customize.serverless.egress.limits.memory: 4Gi
    kserve.customize.serverless.ingress.limits.memory: 4Gi

  # ---

  gating:
    matbench.lts.opensearch.index_prefix: "psap-rhoai."
    matbench.lts.opensearch.instance: intlab

  gating_rehearsal:
    matbench.lts.opensearch.index_prefix: "psap-rhoai.rehearsal."
    matbench.lts.opensearch.instance: intlab

  # ---
  # Get models from integration lab minio instead of AWS S3
  use_intlab_minio:
    secrets.model_s3_cred: intlab-miniocred
    kserve.storage_config.region: "us-east-1"
    kserve.storage_config.endpoint: "minio.app.intlab.redhat.com"
    kserve.storage_config.use_https: "1"
    kserve.storage_config.verify_ssl: "0"

  # ---
  # single-model
  # ---

  cpt_single_model_gating_light:
    extends: [cpt_single_model_gating, gating_rehearsal, use_intlab_minio]
    tests.e2e.models:
    - flan-t5-xl
    tests.e2e.matbenchmark.enabled: true
    tests.e2e.llm_load_test.args.concurrency: [4, 8]
    matbench.lts.horreum.test_name: null
    matbench.lts.opensearch.index: rhoai-kserve-single-light

  cpt_single_model_gating:
    extends: [e2e_perf, gating, 3min, tgis, raw, use_intlab_minio]
    kserve.model.directory_prefix: cpt
    tests.e2e.models:
    - japanese-llama-2-7b-instruct
    - flan-t5-xl
    - flan-t5-xxl
    - llama-2-13b-chat-hf
    - llama-2-70b-chat-hf
    - mpt-7b-instruct2
    - codellama-34b-instruct-hf
    matbench.lts.horreum.test_name: rhoai-kserve-single
    matbench.lts.opensearch.index: rhoai-kserve-single

    tests.e2e.matbenchmark.enabled: true
    # small models will stop at 32
    tests.e2e.llm_load_test.args.concurrency: [1, 2, 4, 8, 16, 32, 64, 96, 128]
    export_artifacts.enabled: true

  # ---

  caikit_single_model_gating:
    extends: [gating, 10min, e2e_gpu, e2e_perf]
    kserve.model.directory_prefix: caikit_tgis
    tests.e2e.models: [flan-t5-small-gpu, flan-t5-large-gpu, bloom-560m, mpt-7b-instruct2]
    matbench.lts.horreum.test_name: rhoai-kserve-single
    matbench.lts.opensearch.index: rhoai-kserve-single

  caikit_single_model_gating_light:
    extends: [caikit_single_model_gating, 5min, gating_rehearsal]

    tests.e2e.models: [flan-t5-small-gpu, flan-t5-large-gpu]
    matbench.lts.horreum.test_name: null
    matbench.lts.opensearch.index: rhoai-kserve-single-light

  # ---
  # multi-model
  # ---

  cpt_multi_model_gating:
    extends: [gating, 5min, e2e_gpu, e2e_multi, raw, cpt_multi_model_models]
    matbench.lts.opensearch.index: rhoai-kserve-multi
    matbench.lts.horreum.test_name: rhoai-kserve-multi
    tests.e2e.limits_equals_requests: false
    tests.e2e.llm_load_test.args.concurrency: 16

  cpt_multi_model_models:
    extends: [tgis, raw, use_intlab_minio]
    kserve.model.directory_prefix: cpt
    tests.e2e.models:
    - mpt-7b-instruct2
    - mpt-7b-instruct2
    - japanese-llama-2-7b-instruct
    - llama-2-13b-chat-hf
    - llama-2-13b-chat-hf
    - kserve-flan-t5-xl-1:
        name: flan-t5-xl
        namespace: kserve-e2e-flan-grouped
        serving_runtime:
          name: kserve-flan-grouped
    - kserve-flan-t5-xl-2:
        name: flan-t5-xl
        namespace: kserve-e2e-flan-grouped
        serving_runtime:
          name: kserve-flan-grouped
    - kserve-flan-t5-xxl:
        name: flan-t5-xxl
        namespace: kserve-e2e-flan-grouped
        serving_runtime:
          name: kserve-flan-grouped

  # multi-model non-cpt

  multi_model_gating_light:
    extends: [cpt_multi_model_gating, gating_rehearsal, 3min, no_gpu]
    kserve.model.directory_prefix: null
    tests.e2e.models:
    - flan-t5-small-hf-cpu
    - flan-t5-small-hf-cpu
    - flan-t5-small-hf-cpu-1:
        name: flan-t5-small-hf-cpu
        namespace: kserve-e2e-grouped
        serving_runtime:
          name: flan-t5-small-hf-cpu
    - flan-t5-small-hf-cpu-2:
        name: flan-t5-small-hf-cpu
        namespace: kserve-e2e-grouped
        serving_runtime:
          name: flan-t5-small-hf-cpu

  # multi-model caikit_tgis

  caikit_multi_model_gating:
    extends: [gating, 10min, e2e_gpu, e2e_multi]
    kserve.model.directory_prefix: caikit_tgis
    matbench.lts.horreum.test_name: rhoai-kserve-multi
    tests.e2e.models:
    - flan-t5-large-gpu-1:
        name: flan-t5-large-gpu
    - flan-t5-small-gpu-1:
        name: flan-t5-small-gpu
    - bloom-560m-1:
        name: bloom-560m
    - mpt-7b-instruct2-1:
        name: mpt-7b-instruct2

    - flan-t5-large-gpu-2:
        name: flan-t5-large-gpu
    - flan-t5-small-gpu-2:
        name: flan-t5-small-gpu
    - bloom-560m-2:
        name: bloom-560m
    - mpt-7b-instruct2-2:
        name: mpt-7b-instruct2
    matbench.lts.opensearch.index: rhoai-kserve-multi

  caikit_multi_model_gating_light:
    extends: [caikit_multi_model_gating, 5min, gating_rehearsal]

    tests.e2e.models: [flan-t5-small-gpu, flan-t5-small-cpu]
    matbench.lts.horreum.test_name: null
    matbench.lts.opensearch.index: rhoai-kserve-multi-light

  # ---
  # longevity
  # ---

  cpt_longevity_gating:
    extends: [cpt_multi_model_models, multi_day_longevity, raw]
    tests.e2e.limits_equals_requests: false
    tests.e2e.llm_load_test.args.concurrency: 16

  longevity:
    tests.e2e.mode: longevity
    tests.e2e.longevity.repeat: 4
    tests.e2e.longevity.delay: 60 # s

    matbench.lts.horreum.test_name: rhoai-kserve-longevity
    matbench.lts.opensearch.index: rhoai-kserve-longevity

  multi_model_a30:
    extends: [raw, use_intlab_minio, tgis]
    kserve.model.directory_prefix: cpt

    tests.e2e.models:
    - flan-t5-xl
    - flan-t5-xl
    - japanese-llama-2-7b-instruct

  hour_longevity:
    extends: [longevity]

    tests.e2e.longevity.repeat: 4
    tests.e2e.longevity.delay: 1200 # 20min

  multi_hour_longevity: # 12h
    extends: [longevity]
    tests.e2e.longevity.repeat: 8
    tests.e2e.longevity.delay: 5400 # 90min

  multi_day_longevity: # 48h
    extends: [longevity]

    tests.e2e.longevity.repeat: 4
    tests.e2e.longevity.delay: 43200 # 12 hours

  # many-model

  many_model_gating:
    extends: [gating, scale_test, customize_smcp]
    matbench.lts.horreum.test_name: rhoai-kserve-many

    tests.scale.model.replicas: 17
    tests.scale.namespace.replicas: 12
    gpu.time_sharing.replicas: 32

    tests.scale.model.name: caikit_tgis/flan-t5-small-gpu-light
    kserve.model.serving_runtime.mute_logs: true
    tests.scale.sleep_factor: 60
    tests.e2e.limits_equals_requests: false
    matbench.lts.opensearch.index: rhoai-kserve-many

  many_model_gating_light:
    extends: [many_model_gating, gating_rehearsal]

    tests.scale.sleep_factor: 1
    tests.scale.model.replicas: 2
    tests.scale.namespace.replicas: 2
    gpu.time_sharing.replicas: 10
    matbench.lts.horreum.test_name: null
    matbench.lts.opensearch.index: rhoai-kserve-many-light

secrets:
  dir:
    name: psap-ods-secret
    env_key: PSAP_ODS_SECRET_PATH
  # name of the file containing the properties of LDAP secrets
  s3_ldap_password_file: s3_ldap.passwords
  keep_cluster_password_file: get_cluster.password
  brew_registry_redhat_io_token_file: brew.registry.redhat.io.token
  model_s3_cred: .awscred
  kserve_model_secret_settings: watsonx-models.yaml
  opensearch_instances: opensearch.yaml
  aws_credentials: .awscred

clusters:
  metal_profiles:
    p42-h03-dgx.rdu3.labs.perfscale.redhat.com: cluster_dgx
    e26-h23-000-r650: cluster_icelake
    bb37-h13-000-r750.rdu3.labs.perfscale.redhat.com: cluster_a30
  create:
    type: single # can be: single, ocp, managed
    keep: false
    name_prefix: kserve-ci
    ocp:
      # list of tags to apply to the machineset when creating the cluster
      tags:
        TicketId: 229
        Project: PSAP/Watsonx/serving/scale/ci-dev
      deploy_cluster:
        target: cluster
      base_domain: psap.aws.rhperfscale.org
      version: 4.13.9
      region: us-west-2
      control_plane:
        type: m6a.xlarge
      workers:
        type: m6a.2xlarge
        count: 2
        spot: false

  sutest:
    is_metal: false
    lab:
      name: null
    compute:
      dedicated: true
      machineset:
        name: workload-pods
        type: g4dn.2xlarge
        count: null
        disk_size: 400 # GB for the root partition
        spot: false
        taint:
          key: only-workload-pods
          value: "yes"
          effect: NoSchedule

  driver:
    is_metal: false
    compute:
      dedicated: true
      machineset:
        name: test-pods
        type: m6i.2xlarge
        count: null
        spot: false
        taint:
          key: only-test-pods
          value: "yes"
          effect: NoSchedule
  cleanup_on_exit: false

rhods:
  catalog:
    image: brew.registry.redhat.io/rh-osbs/iib
    tag: 690058
    channel: fast
    version: 2.8.0
    version_name: rc4
  operator:
    # set to true to stop the RHODS operator
    stop: false
    customize:
      kserve:
        enabled: false
        cpu: 500m
        memory: 500Mi


prepare:
  enabled: true
  operators:
  - name: serverless-operator
    catalog: redhat-operators
    namespace: all
    cleanup:
      crds:
      - knativeservings.operator.knative.dev
      namespaces:
      - knative-eventing
      - knative-serving
  - name: servicemeshoperator
    catalog: redhat-operators
    namespace: all
    cleanup:
      crds:
      - servicemeshmemberrolls.maistra.io
      - servicemeshcontrolplanes.maistra.io
      namespaces:
      - istio-system
  cleanup:
    enabled: true
    crds:
    - InferenceService
    - ServingRuntime

base_image:
  namespace: kserve-user-test-driver
  imagestream: topsail
  repo:
    url: https://github.com/openshift-psap/topsail/
    tag: main
    ref: main
    ref_prefer_pr: true
    dockerfile_path: build/Dockerfile
  extend:
    enabled: true
    local_dockerfile_path: projects/kserve/testing/images/Containerfile.e2e_test_user
    tag: e2e-test-user
  user:
    service_account: ci-artifacts
    role: cluster-admin
  minio:
    bucket_name: kserve-test-bucket

kserve:
  sa_name: sa
  raw_deployment:
    enabled: false
  storage_config:
    name: storage-config
    region: us-east-1
    endpoint: s3.amazonaws.com
    use_https: 1
    verify_ssl: 1

  inference_service:
    validation:
      query_count: 10
      method: caikit.runtime.Nlp.NlpService/TextGenerationTaskPredict
      proto: null
  model:
    directory_prefix: null
    serving_runtime:
      mute_logs: true
      kserve:
        image: quay.io/opendatahub/text-generation-inference:fast
      transformer:
        image: quay.io/opendatahub/caikit-tgis-serving:fast
  customize:
    serverless:
      enabled: false
      egress:
        limits:
          memory: 4Gi
      ingress:
        limits:
          memory: 4Gi
gpu:
  prepare_cluster: true
  time_sharing:
    replicas: 1

tests:
  mode: e2e

  dry_mode: false
  visualize: true
  capture_prom: true
  prom_plot_workload: projects.kserve.visualizations.kserve-prom
  prom_plot_index_suffix: -prom
  scale:
    sleep_factor: 1
    namespace:
      name: kserve-scale-test
      label: topsail.scale-test=true
      replicas: 2

    model:
      consolidated: false
      name: caikit_tgis/flan-t5-small-cpu
      format: caikit
      replicas: 2
  e2e:
    namespace: kserve-e2e
    mode: single # single, longevity or multi
    models:
    - flan-t5-small-hf
    - flan-t5-small-hf
    consolidated_models: {} # will be filled at runtime
    limits_equals_requests: false
    delete_others: true
    validate_model: true
    capture_state: true
    matbenchmark:
      enabled: false
      stop_on_error: true
    llm_load_test:
      enabled: true
      args:
        src_path: projects/llm_load_test/subprojects/llm-load-test/

        duration: 60
        concurrency: 16
        plugin: caikit_client_plugin
        interface: grpc
        streaming: true

      dataset_size:
        small:
          max_input_tokens: 2047
          max_output_tokens: 1024
          max_sequence_tokens: 2048
        large:
          max_input_tokens: 3500
          max_output_tokens: 800
          max_sequence_tokens: 3500
    longevity:
      repeat: 2
      delay: 30 # seconds

matbench:
  preset: null
  workload: projects.kserve.visualizations.kserve-llm
  config_file: plots.yaml
  download:
    mode: prefer_cache
    url:
    url_file:
    # if true, copy the results downloaded by `matbench download` into the artifacts directory
    save_to_artifacts: false
  ignore_exit_code: true
  # directory to plot. Set by topsail/testing/visualize.py before launching the visualization
  test_directory: null
  lts:
    generate: true
    horreum:
      test_name: null
    opensearch:
      export:
        enabled: true
        enabled_on_replot: false
        fail_test_on_fail: true
      instance: smoke
      index: rhoai-kserve-single
      index_prefix: ""

    regression_analyses:
      enabled: false
      enabled_on_replot: false
      # if the regression analyses fail, mark the test as failed
      fail_test_on_regression: true
export_artifacts:
  enabled: false
  bucket: rhoai-cpt-artifacts
  path_prefix: cpt/kserve
  dest: null # will be set by the export code
