# Auto-generated file, do not edit manually ...
# Toolbox generate command: repo generate_ansible_default_settings
# Source component: Fine_Tuning.run_fine_tuning_job

# Parameters
# the name of the fine-tuning job to create
# Mandatory value
fine_tuning_run_fine_tuning_job_name:

# the name of the namespace where the scheduler load will be generated
# Mandatory value
fine_tuning_run_fine_tuning_job_namespace:

# the name of the PVC where the model and dataset are stored
# Mandatory value
fine_tuning_run_fine_tuning_job_pvc_name:

# the name of the model to use inside the /dataset directory of the PVC
# Mandatory value
fine_tuning_run_fine_tuning_job_model_name:

# the name of the dataset to use inside the /model directory of the PVC
# Mandatory value
fine_tuning_run_fine_tuning_job_dataset_name:

# number of replications of the dataset to use, to artificially extend or reduce the fine-tuning effort
fine_tuning_run_fine_tuning_job_dataset_replication: 1

# name of the transformation to apply to the dataset
fine_tuning_run_fine_tuning_job_dataset_transform: null

# the image to use for the fine-tuning container
fine_tuning_run_fine_tuning_job_container_image: quay.io/modh/fms-hf-tuning:01b3824c9aba22d9d0695399681e6f0507840e7f

# the number of GPUs to request for the fine-tuning job
fine_tuning_run_fine_tuning_job_gpu: 0

# the number of RAM gigs to request for to the fine-tuning job (in Gigs)
fine_tuning_run_fine_tuning_job_memory: 10

# the number of CPU cores to request for the fine-tuning job (in cores)
fine_tuning_run_fine_tuning_job_cpu: 1

# if True, sets the 'limits' of the job with the same value as the request.
fine_tuning_run_fine_tuning_job_request_equals_limits: false

# batch size to use for the model fine-tuning training
fine_tuning_run_fine_tuning_job_per_device_train_batch_size: 4

# batch size to use for the model fine-tuning evaluation
fine_tuning_run_fine_tuning_job_per_device_eval_batch_size: 4

# Enables/disables Flash Attention
fine_tuning_run_fine_tuning_job_use_flash_attn: false

# if True, only prepare the environment but do not run the fine-tuning job.
fine_tuning_run_fine_tuning_job_prepare_only: false

# if True, delete the other PyTorchJobs before running
fine_tuning_run_fine_tuning_job_delete_other: false

# number of worker replicas to deploy
fine_tuning_run_fine_tuning_job_worker_replicas: 1
