---
- name: Ensure that the resource kind is supported
  fail: msg="unsupported resource kind ({{ scheduler_generate_load_resource_kind }})"
  when: scheduler_generate_load_resource_kind not in ("job", "pytorchjob", "appwrapper")

- name: Ensure that there are no resource in the namespace
  shell:
    oc delete {{ scheduler_generate_load_resource_kind }} --all -n "{{ scheduler_generate_load_namespace }}" > /dev/null

- name: Ensure that there are no PodGroup in the namespace
  shell:
    oc delete podgroups --all -n "{{ scheduler_generate_load_namespace }}" > /dev/null
  when: scheduler_generate_load_mode == "coscheduling"

- name: Ensure that there are no Pod in the namespace
  shell:
    oc delete pods --all -n "{{ scheduler_generate_load_namespace }}" > /dev/null
# ---

- name: Create the src artifacts directory
  file:
    path: "{{ artifact_extra_logs_dir }}/src/"
    state: directory
    mode: '0755'

- name: Create the generator artifacts directory
  file:
    path: "{{ artifact_extra_logs_dir }}/generator-artifacts/"
    state: directory
    mode: '0755'

- name: Create a configmap for the beginning of the test timestamp
  shell:
    oc delete cm start end -n "{{ scheduler_generate_load_namespace }}" --ignore-not-found;
    oc create configmap start -n "{{ scheduler_generate_load_namespace }}" ;

- name: Generate scheduler load
  block:
  - name: Run the load test
    debug: msg="Load generator running in the next task, expect some delays (timespan={{ scheduler_generate_load_timespan }}min)... (mode={{ scheduler_generate_load_mode }})"

  - name: Generate the scheduler load
    command:
      python3 "{{ scheduler_generate_load_scheduler_load_generator }}"
        --dry_run "False"
        --namespace "{{ scheduler_generate_load_namespace }}"
        --base_name "{{ scheduler_generate_load_base_name }}"
        --count "{{ scheduler_generate_load_count }}"
        --job_template_name "{{ scheduler_generate_load_job_template_name }}"
        --mode "{{ scheduler_generate_load_mode }}"
        --pod_count "{{ scheduler_generate_load_pod_count }}"
        --pod_runtime "{{ scheduler_generate_load_pod_runtime }}"
        --pod_requests "{{ scheduler_generate_load_pod_requests }}"
        --timespan "{{ scheduler_generate_load_timespan }}"
        --distribution "{{ scheduler_generate_load_distribution }}"
        --kueue_queue "{{ scheduler_generate_load_kueue_queue }}"
    environment:
      ARTIFACT_DIR: "{{ artifact_extra_logs_dir }}/generator-artifacts"

  - name: Define the variables
    set_fact:
      success_states: "{{ scheduler_generate_load_states_target | map('to_json') | join(', ') }}"
      failed_states: "{{ scheduler_generate_load_states_unexpected | map('to_json') | join(', ') }}"

  - name: Wait for the AppWrappers to complete
    shell: |
      set -o pipefail; set -e;
      appwrappers_json=$(oc get appwrappers -n {{ scheduler_generate_load_namespace }} -ojson)

      if [[ {{ scheduler_generate_load_count }} -lt 50 ]]; then
        jq '.items[] | .metadata.name + " ==> "+ .status.state' -r <<< $appwrappers_json
      else
        echo "Too many appwrappers, hiding the individual status ..."
      fi

      appwrapper_count=$(jq '.items | length' <<< $appwrappers_json)
      appwrapper_successes=$(jq '[.items[] | select(.status.state | IN({{ success_states }}))] | length' <<< $appwrappers_json)
      appwrapper_failed=$(jq '[.items[] | select(.status.state | IN({{ failed_states }}))] | length' <<< $appwrappers_json)

      if [[ "$appwrapper_failed" != 0 ]]; then
        echo "Found $appwrapper_failed AppWrapper(s) in one of the unexpected states '{{ failed_states }}' , aborting."
        exit 1 # fatal
      fi

      if [[ "$appwrapper_count" != "$appwrapper_successes" ]]; then
         echo "Only $appwrapper_successes/$appwrapper_count AppWrappers are in the expected states '{{ success_states }}'. Continue waiting ...."
         exit 2 # retry
      fi

      echo "All the AppWrappers have completed successfully. All done."
      exit 0 # done
    register: appwrappers_completed
    retries: 120
    delay: 30
    # until fatal or done
    until: appwrappers_completed.rc == 1 or appwrappers_completed.rc == 0
    # failed when fatal
    failed_when: appwrappers_completed.rc != 0
    when: scheduler_generate_load_mode == "mcad"

  - name: Define the status path
    set_fact:
      status_path: '{%if scheduler_generate_load_resource_kind == "job" %}.status{% else %}.status.replicaStatuses.Master{% endif %}'
    when: scheduler_generate_load_resource_kind == "job" or scheduler_generate_load_resource_kind == "pytorchjob"

  - name: Define if the test is small
    set_fact:
      is_small_test: '{% if scheduler_generate_load_count < 50 %}true{% else %}false{% endif %}'
      is_large_test: '{% if scheduler_generate_load_count > 150 %}true{% else %}false{% endif %}'

  - name: Wait for the Jobs to complete
    shell: |
      set -o pipefail; set -e;
      jobs_json=$(oc get {{ scheduler_generate_load_resource_kind }} -n {{ scheduler_generate_load_namespace }} -ojson)

      {% if is_small_test %}
        oc get {{ scheduler_generate_load_resource_kind }},pods -n {{ scheduler_generate_load_namespace }} --no-headers
      {% else %}
        echo "Too many {{ scheduler_generate_load_resource_kind }}, hiding the individual status ..."
      {% endif %}

      jobs_count=$(jq '.items | length' <<< $jobs_json)
      jobs_active=$(jq '[.items[] | select({{ status_path }}.active and {{ status_path }}.active != 0)] | length' <<< $jobs_json)
      jobs_failed=$(jq '[.items[] | select({{ status_path }}.failed and {{ status_path }}.failed != 0)] | length' <<< $jobs_json)

      {% if scheduler_generate_load_resource_kind == "pytorchjob" %}
      jobs_suspended=$(jq '[.items[] | select(.spec.runPolicy.suspend == true)] | length' <<< $jobs_json)
      {% endif %}

      if [[ "$jobs_failed" != 0 ]]; then
        echo "Found $jobs_failed failed {{ scheduler_generate_load_resource_kind }}(s), aborting."
        exit 1 # fatal
      fi

      {% if scheduler_generate_load_resource_kind == "pytorchjob" %}
      if [[ "$jobs_suspended" != 0 ]]; then
         echo "$jobs_active/$jobs_count {{ scheduler_generate_load_resource_kind }} still active."
         echo "$jobs_suspended/$jobs_count {{ scheduler_generate_load_resource_kind }} still suspended. Continue waiting ...."
         exit 2 # retry
      fi
      {% endif %}

      if [[ "$jobs_active" != 0 ]]; then
         echo "$jobs_active/$jobs_count {{ scheduler_generate_load_resource_kind }} still active. Continue waiting ...."
         exit 2 # retry
      fi

      echo "All the {{ scheduler_generate_load_resource_kind }}s have completed successfully. All done."
      exit 0 # done
    register: jobs_completed
    retries: 180
    delay: 30
    # until fatal or done
    until: jobs_completed.rc == 1 or jobs_completed.rc == 0
    # failed when fatal
    failed_when: jobs_completed.rc != 0
    when: scheduler_generate_load_resource_kind == "job" or scheduler_generate_load_resource_kind == "pytorchjob"

  - name: Count how many resource succeeded
    shell:
      set -o pipefail;
      oc get {{ scheduler_generate_load_resource_kind }} -n {{ scheduler_generate_load_namespace }} -ojson | jq '[.items[] | select({{ status_path }}.succeeded)] | length'
    register: job_succeeded
    failed_when: job_succeeded.stdout | int != scheduler_generate_load_count
    when: scheduler_generate_load_resource_kind == "job" or scheduler_generate_load_resource_kind == "pytorchjob"

  always:
  - name: Create a configmap for the end of the test timestamp
    shell:
      oc create configmap end -n "{{ scheduler_generate_load_namespace }}" ;
      oc get cm start end -oyaml -n "{{ scheduler_generate_load_namespace }}" > "{{ artifact_extra_logs_dir }}/start_end_cm.yaml"

  - name: Capture the state of the Jobs
    shell: |
      oc get {{ scheduler_generate_load_resource_kind }} -ojson -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/{{ scheduler_generate_load_resource_kind }}.json"
      oc get {{ scheduler_generate_load_resource_kind }} -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/{{ scheduler_generate_load_resource_kind }}.status"
      {% if not is_large_test %}
      oc get {{ scheduler_generate_load_resource_kind }} -oyaml -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/{{ scheduler_generate_load_resource_kind }}.yaml"
      oc describe {{ scheduler_generate_load_resource_kind }} -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/{{ scheduler_generate_load_resource_kind }}.desc"
      {% endif %}
    ignore_errors: true

  - name: Capture the state of the Pods
    shell: |
      oc get pods -ojson -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/pods.json"
      oc get pods -owide -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/pods.status"
      {% if not is_large_test %}
      oc get pods -oyaml -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/pods.yaml"1
      oc describe pods -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/pods.desc"
      {% endif %}
    ignore_errors: true

  - name: Create the test Pod logs directory
    file:
      path: "{{ artifact_extra_logs_dir }}/logs"
      state: directory
      mode: '0755'

  - name: Get the names of the tester_pods
    command:
      oc get pods -oname -n {{ scheduler_generate_load_namespace }}
    register: pod_names_cmd
    ignore_errors: true
    # mute to reduce the log length
    no_log: true

  - name: Get the logs of the tester Pod
    shell:
      oc logs {{ item }} --all-containers --prefix
         -n {{ scheduler_generate_load_namespace }}
         > "{{ artifact_extra_logs_dir }}/logs/$(basename "{{ item }}").log"
    loop: "{{ pod_names_cmd.stdout_lines }}"
    ignore_errors: true
    # mute to reduce the log length
    no_log: true

  - name: Capture the state of the workloads
    shell: |
      oc get workloads -ojson -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/workloads.json"
      oc get workloads -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/workloads.status"
      {% if not is_large_test %}
      oc get workloads -oyaml -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/workloads.yaml"
      oc describe workloads -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/workloads.desc"
      {% endif %}
    when: scheduler_generate_load_mode == "kueue"
    ignore_errors: true

  - name: Capture the state of the podgroups
    shell: |
      oc get podgroups -ojson -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/podgroups.json"
      oc get podgroups -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/podgroups.status"
      {% if not is_large_test %}
      oc get podgroups -oyaml -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/podgroups.yaml"
      oc describe podgroups -n {{ scheduler_generate_load_namespace }} > "{{ artifact_extra_logs_dir }}/podgroups.desc"
      {% endif %}
    when: scheduler_generate_load_mode == "coscheduling"
    ignore_errors: true

  - name: Capture the nodes of the cluster
    shell:
      oc get nodes -ojson > "{{ artifact_extra_logs_dir }}/nodes.json"
