---

- name: Check that pipelines_run_kfp_notebook_notebook_directory is defined
  fail: msg="Bailing out. This role requires 'pipelines_run_kfp_notebook_notebook_directory'"
  when: not pipelines_run_kfp_notebook_notebook_directory

- name: Ensure that the following path is a directory {{ pipelines_run_kfp_notebook_notebook_directory }}
  stat:
    path: "{{ pipelines_run_kfp_notebook_notebook_directory }}"
  register: directory_stats
  failed_when: not directory_stats.stat.exists or not directory_stats.stat.isdir

- name: Ensure that the following path is a file {{ pipelines_run_kfp_notebook_notebook_directory + '/' + pipelines_run_kfp_notebook_notebook_filename }}
  stat:
    path: "{{ pipelines_run_kfp_notebook_notebook_directory }}/{{ pipelines_run_kfp_notebook_notebook_filename }}"
  register: file_stats
  failed_when: not file_stats.stat.exists

- name: Get the stats of {{ pipelines_run_kfp_notebook_notebook_directory }}
  stat:
    path: "{{ pipelines_run_kfp_notebook_notebook_directory }}"
  register: directory_stats

- name: Fail if the following path is not a directory {{ pipelines_run_kfp_notebook_notebook_directory }}
  fail: msg="'{{ pipelines_run_kfp_notebook_notebook_directory }}' isn't a reachable directory."
  when: not directory_stats.stat.exists or not directory_stats.stat.isdir

- name: Create the src artifacts directory
  file:
    path: "{{ artifact_extra_logs_dir }}/src/"
    state: directory
    mode: '0755'

- name: Store the listing of the notebook directory
  shell:
    find "{{ pipelines_run_kfp_notebook_notebook_directory }}"
      > "{{ artifact_extra_logs_dir }}/src/notebook-files.list"

- name: Store the content of the notebook directory
  ansible.builtin.copy:
    src: "{{ pipelines_run_kfp_notebook_notebook_directory }}/"
    dest: "{{ artifact_extra_logs_dir }}/src/notebook-files"
    mode: '0644'

- name: Lookup the imagestream tag
  when: pipelines_run_kfp_notebook_imagestream_tag == None
  shell:
    set -o pipefail;
    oc get is/{{ pipelines_run_kfp_notebook_imagestream }}
       -n redhat-ods-applications
       --no-headers
       | awk '{print $3}'
       | tr "," "\n"
       | sort -r
       | head -1
  register: image_tag_cmd
  failed_when: not image_tag_cmd.stdout

- name: Save the imagestream tag
  set_fact:
    image_tag: "{% if pipelines_run_kfp_notebook_imagestream_tag != None %}{{ pipelines_run_kfp_notebook_imagestream_tag }}{% else %}{{ image_tag_cmd.stdout }}{% endif %}"

- name: Set the name of the token secret
  set_fact:
    secret_token_name: "secret-token"

- name: Get the image address
  command:
    oc get istag {{ pipelines_run_kfp_notebook_imagestream }}:{{ image_tag }}
       -ojsonpath={.image.dockerImageReference}
       -n redhat-ods-applications
  register: rhods_image_address_cmd

- name: Get the name of the current project
  command:
    oc project --short
  register: project_name_cmd
  when: not pipelines_run_kfp_notebook_namespace

- name: Define the test environment
  set_fact:
    notebook_name: pipeline-notebook
    notebook_container: pipeline-notebook
    notebook_namespace: "{% if pipelines_run_kfp_notebook_namespace | length > 0 %}{{ pipelines_run_kfp_notebook_namespace }}{% else %}{{ project_name_cmd.stdout }}{% endif %}"
    notebook_src_template_dest: "{{ artifact_extra_logs_dir }}/src/000_rhods_notebook.yaml"
    notebook_file_cm_name: pipeline-notebook-files
    capture_prom_db: pipelines_run_kfp_notebook_capture_prom_db
    notebook_image_address: "{{ rhods_image_address_cmd.stdout }}"

- name: Define the test environment
  set_fact:
    notebook_search_labels: "-lci-artifacts.single-notebook-perf=true -lapp={{ notebook_name }}"

- name: Delete the notebook files ConfigMap, if it exists
  command:
    oc delete cm "{{ notebook_file_cm_name }}"
       -n "{{ notebook_namespace }}"
       --ignore-not-found

- name: Prepare the notebook files ConfigMap
  command:
    oc create cm "{{ notebook_file_cm_name }}"
       -n "{{ notebook_namespace }}"
       --from-file="{{ pipelines_run_kfp_notebook_notebook_directory }}"
# ^^^ may fail silently if the directory is invalid
# but Task 'Store the listing of the notebook directory' will catch it earlier

- name: Compute the DSP application name
  shell:
    set -o pipefail;
    oc get dspa -oname -n "{{ notebook_namespace }}" | head -1 | cut -d/ -f2
  register: dspa_name_cmd
  when: not pipelines_run_kfp_notebook_dsp_application_name
  failed_when: not dspa_name_cmd.stdout

- name: Save the DSP application name
  set_fact:
    dspa_application_name: "{% if pipelines_run_kfp_notebook_dsp_application_name %}{{ pipelines_run_kfp_notebook_dsp_application_name }}{% else %}{{ dspa_name_cmd.stdout }}{% endif %}"

- name: Compute the DSP address
  command:
    oc get routes -n {{ notebook_namespace }} ds-pipeline-{{ dspa_application_name }} --template=\{\{.spec.host\}\}
  retries: 30
  delay: 10
  until: dsp_route_cmd.rc == 0
  register: dsp_route_cmd

- name: Save the DSP route
  set_fact:
    dsp_route: "https://{{ dsp_route_cmd.stdout }}"

- name: Instantiate the notebook template
  template:
    src: "{{ pipelines_run_kfp_notebook_benchmark_notebook_template }}"
    dest: "{{ notebook_src_template_dest }}"
    mode: '0700'

- name: Delete the notebook, if it exists
  command:
    oc delete
       -f "{{ notebook_src_template_dest }}"
       --ignore-not-found
       -n "{{ notebook_namespace }}"

- name: Delete the secret token, if it exists
  command: oc delete secret "{{ secret_token_name }}" -n "{{ notebook_namespace }}" --ignore-not-found
  failed_when: false

# ---

- name: Save the DSP route
  set_fact:
    sa_name: pipeline-sa
    sa_cluster_role: cluster-admin

- name: Create the service account that will be used in the Notebook
  shell:
    set -o pipefail;
    oc create serviceaccount "{{ sa_name }}"
       -n "{{ notebook_namespace }}"
       --dry-run=client -oyaml
       | tee "{{ artifact_extra_logs_dir }}/src/serviceaccount.yaml"
       | oc apply -f-

- name: Grant all the privileges to the service account
  shell:
    set -o pipefail;
    oc adm policy add-cluster-role-to-user "{{ sa_cluster_role }}"
       -n "{{ notebook_namespace }}"
       -z "{{ sa_name }}"
       --dry-run=client -oyaml
       | tee "{{ artifact_extra_logs_dir }}/src/clusterrolebinding.yaml"
       | oc apply -f-

# ---

- name: Cleanup the Prometheus database of the cluster
  when: capture_prom_db | bool
  include_role:
    name: cluster_prometheus_db
  vars:
    cluster_prometheus_db_mode: reset

- name: Create the notebook artifacts directory
  file:
    path: "{{ artifact_extra_logs_dir }}/notebook-artifacts/"
    state: directory
    mode: '0755'

- name: Delete the existing workflows/pipelines
  command:
    oc delete workflows.argoproj.io --all -n "{{ notebook_namespace }}"

# ---

- name: Run the test notebook
  block:
  - name: Create the secret token
    shell:
      oc create secret generic "{{ secret_token_name }}"
         "--from-literal=token=$(oc create token '{{ sa_name }}' -n '{{ notebook_namespace }}')"
         -n "{{ notebook_namespace }}"
    register: create_secret_token_cmd
    failed_when: '"no token is currently in use for this session" in create_secret_token_cmd.stderr'

  - name: Create the test notebook
    command:
      oc create
         -f "{{ notebook_src_template_dest }}"
         -n "{{ notebook_namespace }}"

  - name: Wait for the Notebook Pod to start running
    shell:
      set -o pipefail;
      oc get pod {{ notebook_search_labels }}
         --ignore-not-found
         -n "{{ notebook_namespace }}"
         --no-headers | awk '{print $3}'
    register: wait_notebook_pod_start
    retries: 20
    delay: 15
    until: wait_notebook_pod_start.stdout == "Running" or wait_notebook_pod_start.stdout == "CrashLoopBackOff"
    failed_when: wait_notebook_pod_start.stdout != "Running"

  - name: Wait for the Notebook Pod to be ready
    shell:
      set -o pipefail;
      oc get pod {{ notebook_search_labels }}
         -n "{{ notebook_namespace }}"
         --no-headers | awk '{print $2}'
    register: wait_notebook_pod_ready
    retries: 12
    delay: 5
    until: wait_notebook_pod_ready.stdout == "2/2"

  - name: Get the notebook Pod name
    command:
      oc get pod {{ notebook_search_labels }}
        -oname
        -n "{{ notebook_namespace }}"
    register: notebook_pod_name_cmd
    failed_when: not notebook_pod_name_cmd.stdout
    # ---

  - name: Move the notebook files to HOME
    shell:
      oc -n "{{ notebook_namespace }}"
         -c "{{ notebook_container }}"
         rsh "{{ notebook_pod_name_cmd.stdout }}"
         bash -c 'cp -v "$NOTEBOOK_FILES"/* . && mkdir -p results'

  - name: Run the notebook
    shell:
      oc -n "{{ notebook_namespace }}"
         -c "{{ notebook_container }}"
         rsh "{{ notebook_pod_name_cmd.stdout }}"
         bash -exc 'jupyter nbconvert --to notebook --execute "$NOTEBOOK_FILENAME"
              && cp "$(basename "$NOTEBOOK_FILENAME" .ipynb).nbconvert.ipynb" $(basename "$NOTEBOOK_FILENAME" .ipynb).ipynb
              && mv "$(basename "$NOTEBOOK_FILENAME" .ipynb).nbconvert.ipynb" results/$(basename "$NOTEBOOK_FILENAME" .ipynb).executed.ipynb
              && jupyter nbconvert --to html results/$(basename "$NOTEBOOK_FILENAME" .ipynb).executed.ipynb'
    register: notebook_execution

  - name: Wait for the pipeline execution to complete
    shell:
      set -o pipefail;
      oc get workflow.argoproj.io -ojson -n "{{ notebook_namespace }}" | jq .items[0].status.phase -r
    register: workflow_phase_cmd
    retries: 120
    delay: 10
    until: workflow_phase_cmd.stdout and "Running" not in workflow_phase_cmd.stdout and "Pending" not in workflow_phase_cmd.stdout

  - name: Check if the pipeline ended in Failure
    fail_when: '"Failed" in workflow_phase_cmd.stdout'

  - name: Generate MatrixBenchmark exit code file
    shell:
      echo 0 > "{{ artifact_extra_logs_dir }}/exit_code"

  always:
  - name: Delete the secret token
    command: oc delete secret/secret_token_name -n "{{ notebook_namespace }}" --ignore-not-found
    failed_when: false

  - name: Capture the artifacts
    include_tasks: artifacts.yml
    when: pipelines_run_kfp_notebook_capture_artifacts | bool

  - name: Generate MatrixBenchmark settings file
    shell: |
      cat <<EOF > "{{ artifact_extra_logs_dir }}/settings"
      notebook_file_name={{ pipelines_run_kfp_notebook_notebook_filename }}
      EOF
    ignore_errors: true

- name: Delete the notebook
  command:
    oc delete
       -f "{{ notebook_src_template_dest }}"
       -n "{{ notebook_namespace }}"
  ignore_errors: true
  when: pipelines_run_kfp_notebook_stop_on_exit | bool
