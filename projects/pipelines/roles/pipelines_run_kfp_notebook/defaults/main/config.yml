# Auto-generated file, do not edit manually ...
# Toolbox generate command: repo generate_ansible_default_settings
# Source component: Pipelines.run_kfp_notebook

# Parameters
# Namespace in which the notebook will be deployed, if not deploying with RHODS. If empty, use the project return by 'oc project --short'.
pipelines_run_kfp_notebook_namespace:

# The name of the DSPipelines Application to use. If empty, lookup the application name in the namespace.
pipelines_run_kfp_notebook_dsp_application_name:

# Imagestream to use to look up the notebook Pod image.
pipelines_run_kfp_notebook_imagestream: s2i-generic-data-science-notebook

# Imagestream tag to use to look up the notebook Pod image. If emtpy and and the image stream has only one tag, use it. Fails otherwise.
pipelines_run_kfp_notebook_imagestream_tag:

# A prefix to add the name of the notebook to differential notebooks in the same project
pipelines_run_kfp_notebook_notebook_name:

# Directory containing the files to mount in the notebook.
pipelines_run_kfp_notebook_notebook_directory: testing/pipelines/notebooks/hello-world

# Name of the ipynb notebook file to execute with JupyterLab.
pipelines_run_kfp_notebook_notebook_filename: kfp_hello_world.ipynb

# Number of times to run the pipeline
pipelines_run_kfp_notebook_run_count: 0

# Number of seconds to wait before trigger the next run from the notebook
pipelines_run_kfp_notebook_run_delay: 0

# If False, keep the notebook running after the test.
pipelines_run_kfp_notebook_stop_on_exit: true

# If False, disable the post-test artifact collection.
pipelines_run_kfp_notebook_capture_artifacts: true

# If True, captures the Prometheus DB of the systems.
pipelines_run_kfp_notebook_capture_prom_db: false

# whether to capture extra descriptions and YAML's
pipelines_run_kfp_notebook_capture_extra_artifacts: true

# Whether to wait for one runs completion before starting the next
pipelines_run_kfp_notebook_wait_for_run_complete: false
