- name: Ensure the GPU Operator package is available
  block:
  - name: Capture the state of the CatalogSource/certified-operators (debug)
    command:
      oc get -oyaml CatalogSource/certified-operators
         -n openshift-marketplace
         '-ojsonpath={.status.connectionState.lastObservedState}{"\n"}'
    failed_when: false

  - name: Ensure that the GPU Operator PackageManifest exists
    command: oc get packagemanifests/gpu-operator-certified -n openshift-marketplace
    failed_when: false
    register: gpu_operator_package_available

  - name: Wait for the GPU Operator to be available or its catalog to be fully populated
    when: gpu_operator_package_available.rc != 0
    shell:
      oc get packagemanifests/gpu-operator-certified -n openshift-marketplace
         ||
      test $(oc get -oyaml CatalogSource/certified-operators
                -n openshift-marketplace
                '-ojsonpath={.status.connectionState.lastObservedState}{"\n"}') == "READY"
    register: gpu_operator_package_wait
    until: gpu_operator_package_wait.rc == 0
    retries: 15
    delay: 30

  - name: Ensure that the GPU Operator PackageManifest exists
    command: oc get packagemanifests/gpu-operator-certified -n openshift-marketplace

  - name: Save the GPU Operator PackageManifest (debug)
    shell:
      oc get packagemanifests/gpu-operator-certified -n openshift-marketplace -oyaml
      > {{ artifact_extra_logs_dir }}/gpu_operator_packagemanifest.yml

  - name: Store the GPU Operator PackageManifest
    shell:
      oc get packagemanifests/gpu-operator-certified -n openshift-marketplace -ojson
      > {{ artifact_extra_logs_dir }}/gpu_operator_packagemanifest.json

  rescue:
  - name: Mark the failure as flake
    shell:
      echo "Failed because of the GPU Operator packagemanifest not available"
           > "{{ artifact_dir }}/FLAKE"

  - name: Failing because of previous error
    fail: msg="Failing because of the GPU Operator packagemanifest not available"

- name: Store the CSV version
  when: gpu_operator_operatorhub_version | length > 0
  set_fact:
    gpu_operator_csv_name: "gpu-operator-certified.v{{ gpu_operator_operatorhub_version }}"

- name: "Fetch the channel name for the requested version ({{ gpu_operator_operatorhub_version }})"
  when: gpu_operator_operatorhub_version != "" and not gpu_operator_operatorhub_channel
  block:

  - name: Fetch the channel name for the requested CSV
    command:
      jq -r
         '.status.channels[] | select(.currentCSV=="{{ gpu_operator_csv_name }}") | .name'
         "{{ artifact_extra_logs_dir }}/gpu_operator_packagemanifest.json"
    register: gpu_operator_channel_cmd

  - name: Fail if the channel of the CSV could not be found
    fail: msg="Could not find the channel for the requested GPU Operator version '{{ gpu_operator_operatorhub_version }}'"
    when: not gpu_operator_channel_cmd.stdout

  - name: Store the channel name
    set_fact:
      gpu_operator_operatorhub_channel: "{{ gpu_operator_channel_cmd.stdout }}"

- name: Fetch the default channel name
  when: not gpu_operator_operatorhub_channel
  block:
  - name: Get the default channel of the GPU Operator on OperatorHub
    command:
      jq -r .status.defaultChannel {{ artifact_extra_logs_dir }}/gpu_operator_packagemanifest.json
    register: gpu_operator_channel_cmd

  - name: Store the channel name
    set_fact:
      gpu_operator_operatorhub_channel: "{{ gpu_operator_channel_cmd.stdout }}"

- name: Fetch the GPU Operator version and store its CSV name
  when: not gpu_operator_operatorhub_version
  block:
  - name: "Get the version of the GPU Operator on OperatorHub on channel {{ gpu_operator_operatorhub_channel }}"
    command:
      jq -r
         '.status.channels[] | select(.name == "{{ gpu_operator_operatorhub_channel }}") | .currentCSV'
         {{ artifact_extra_logs_dir }}/gpu_operator_packagemanifest.json
    register: gpu_operator_csv_name_cmd

  - name: Fail if current CSV not found for the channel
    fail: msg="Could not find the current CSV for the GPU Operator Channel '{{ gpu_operator_operatorhub_channel }}'"
    when: not gpu_operator_csv_name_cmd.stdout

  - name: Store the CSV version
    set_fact:
      gpu_operator_csv_name: "{{ gpu_operator_csv_name_cmd.stdout }}"

- name: Store the version of the GPU Operator that will be installed
  shell: echo "{{ gpu_operator_csv_name }}" > {{ artifact_extra_logs_dir }}/gpu_operator_csv_name.txt

- name: "Create the OperatorHub subscription for {{ gpu_operator_csv_name }}"
  debug: msg="{{ gpu_operator_csv_name }}"

- name: Store the CSV version
  set_fact:
    startingCSV: "{{ gpu_operator_csv_name }}"

- name: "Create the OperatorHub subscription for {{ gpu_operator_csv_name }}"
  template:
    src: "{{ gpu_operator_operatorhub_sub }}"
    dest: "{{ artifact_extra_logs_dir }}/gpu_operator_sub.yml"
    mode: 0400

- name: Instantiate the OperatorHub subscription
  command: oc create -f "{{ artifact_extra_logs_dir }}/gpu_operator_sub.yml"

- block:
  - name: Find the GPU Operator OperatorHub InstallPlan
    # TODO: use 'oc get installplan -loperators.coreos.com/gpu-operator-certified.openshift-operators'
    # when we get rid of OCP 4.5 support
    command:
      oc get subscriptions.operators.coreos.com/gpu-operator-certified
         -n openshift-operators
         -ojsonpath={@.status.installPlanRef.name}
    register: gpu_operator_installplan_name
    until: gpu_operator_installplan_name.stdout != ""
    retries: 20
    delay: 30

  - name: Approve the GPU Operator OperatorHub InstallPlan
    command:
      oc patch InstallPlan/{{ gpu_operator_installplan_name.stdout }}
         -n openshift-operators
         --type merge
         --patch '{"spec":{"approved":true }}'

  - name: Wait for the GPU Operator OperatorHub ClusterServiceVersion
    command:
      oc get ClusterServiceVersion/{{ gpu_operator_csv_name }}
         -oname
         -n openshift-operators
    register: gpu_operator_wait_csv
    until: gpu_operator_wait_csv.stdout != ""
    retries: 40
    delay: 30

  rescue:
  - name: Capture the Catalog Operator logs (debug)
    shell:
      oc logs deployment.apps/catalog-operator
         -n openshift-operator-lifecycle-manager
         > {{ artifact_extra_logs_dir }}/catalog_operator.log
    failed_when: false

  - name: Indicate where the Catalog-operator logs have been saved
    debug: msg="The logs of Catalog Operator have been saved in {{ artifact_extra_logs_dir }}/catalog_operator.log"

  - name: Failed because the GPU Operator could not be install from the Catalog Operator
    fail: msg="Failed because the GPU Operator could not be install from the Catalog Operator"

- name: Store the YAML of the GPU Operator CSV that being installed
  shell:
    oc get ClusterServiceVersion/{{ gpu_operator_csv_name }}
       -oyaml
       -n openshift-operators
       > {{ artifact_extra_logs_dir }}/gpu_operator_csv.yml
