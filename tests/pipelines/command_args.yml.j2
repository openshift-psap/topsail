{% set secrets_location = false | or_env(secrets.dir.env_key) %}
{% if not secrets_location %}
  {{ ("ERROR: secrets_location must be defined (secrets.dir.name="+ secrets.dir.name|string +" or env(secrets.dir.env_key=" + secrets.dir.env_key|string + ")) ") | raise_exception }}
{% endif %}
{% set s3_ldap_password_location = secrets_location + "/" + secrets.s3_ldap_password_file %}

server deploy_ldap:
  idp_name: {{ ldap.idp_name }}
  secret_properties_file: {{ s3_ldap_password_location }}
  username_count: {{ ldap.users.count }}
  username_prefix: {{ ldap.users.prefix }}

server undeploy_ldap:
  idp_name: {{ ldap.idp_name }}

rhods deploy_ods:
  catalog_image: {{ rhods.catalog.image }}
  tag: {{ rhods.catalog.tag }}
  channel: {{ rhods.catalog.channel }}
  version: {{ rhods.catalog.version }}

pipelines deploy_application:
  namespace: {{ rhods.pipelines.namespace }}
  name: {{ rhods.pipelines.application.name }}

sutest/cluster set_scale:
  instance_type: {{ clusters.sutest.compute.machineset.type }}
  name: {{ clusters.sutest.compute.machineset.name }}
{% if clusters.sutest.compute.dedicated %}
  taint: {{ clusters.sutest.compute.machineset.taint.key }}={{ clusters.sutest.compute.machineset.taint.value }}:{{ clusters.sutest.compute.machineset.taint.effect }}
{% endif %}
  scale: SET_AT_RUNTIME

driver/cluster set_scale:
  instance_type: {{ clusters.driver.compute.machineset.type }}
  name: {{ clusters.driver.compute.machineset.name }}
{% if clusters.driver.compute.dedicated %}
  taint: {{ clusters.driver.compute.machineset.taint.key }}={{ clusters.driver.compute.machineset.taint.value }}:{{ clusters.driver.compute.machineset.taint.effect }}
{% endif %}
  scale: SET_AT_RUNTIME

sutest/cluster set_project_annotation/pipelines_node_selector:
  key: openshift.io/node-selector
  value: "{{ clusters.sutest.compute.machineset.taint.key }}={{ clusters.sutest.compute.machineset.taint.value }}"
  project: {{ rhods.pipelines.namespace }}

sutest/cluster set_project_annotation/pipelines_toleration:
  key: scheduler.alpha.kubernetes.io/defaultTolerations
  value: '[{\"operator\": \"Exists\", \"effect\": \"{{ clusters.sutest.compute.machineset.taint.effect }}\", \"key\": \"{{ clusters.sutest.compute.machineset.taint.key }}\"}]'
  project: {{ rhods.pipelines.namespace }}

driver/cluster set_project_annotation/test_node_selector:
  key: openshift.io/node-selector
  value: "{{ clusters.driver.compute.machineset.taint.key }}={{ clusters.driver.compute.machineset.taint.value }}"
  project: {{ base_image.namespace }}

driver/cluster set_project_annotation/test_toleration:
  key: scheduler.alpha.kubernetes.io/defaultTolerations
  value: '[{\"operator\": \"Exists\", \"effect\": \"{{ clusters.driver.compute.machineset.taint.effect }}\", \"key\": \"{{ clusters.driver.compute.machineset.taint.key }}\"}]'
  project: {{ base_image.namespace }}

pipelines run_kfp_notebook:
  run_count: {{ tests.pipelines.runs_per_pipeline }}
  run_delay: {{ tests.pipelines.run_delay }}
  notebook_name: {{ rhods.pipelines.notebook.name }}
  namespace: {{ rhods.pipelines.namespace }}
  imagestream: {{ rhods.pipelines.workbench.imagestream }}
  imagestream_tag: {% if rhods.pipelines.workbench.imagestream_tag %}"{{ rhods.pipelines.workbench.imagestream_tag }}"{% else %}null{% endif %}
  dsp_application_name: {{ rhods.pipelines.application.name }}
  notebook_filename: {{ tests.pipelines.notebook_filename }}
  notebook_directory: {{ tests.pipelines.notebook_directory }}
  capture_extra_artifacts: {{ tests.pipelines.capture_extra_artifacts }}
  wait_for_run_completion: {{ tests.pipelines.wait_for_run_completion }}

pipelines capture_state:
  namespace: {{ rhods.pipelines.namespace }}
  dsp_application_name: {{ rhods.pipelines.application.name }}
  user_id: SET_AT_RUNTIME
  capture_extra_artifacts: {{ tests.pipelines.capture_extra_artifacts }}

base_image/cluster build_push_image:
  namespace: "{{ base_image.namespace }}"
  image_local_name: "{{ base_image.imagestream }}"
  tag: "{{ base_image.repo.tag }}"
  _istag: "{{ base_image.imagestream }}:{{ base_image.repo.tag }}"

  git_repo: "{{ base_image.repo.url }}"
  git_ref: "{{ base_image.repo.ref }}" # may be overwritten at runtime with the PR ref
  dockerfile_path: "{{ base_image.repo.dockerfile_path }}"

server deploy_redis_server:
{% set redis_internal_address = "redis."+base_image.namespace+".svc" %}
  namespace: "{{ base_image.namespace }}"

local_ci run_multi:
  user_count: "{{ tests.pipelines.user_count }}"
  namespace: "{{ base_image.namespace }}"
  istag: "{{ base_image.imagestream }}:{{ base_image.repo.tag }}"
  service_account: "{{ base_image.user.service_account }}"
  state_signal_redis_server: {{ redis_internal_address }}

  secret_name: "{{ secrets.dir.name }}"
  secret_env_key: "{{ secrets.dir.env_key }}"

  ci_command: "pipelines test run_one"

  retrieve_artifacts: true
  minio_bucket_name: "{{ base_image.minio.bucket_name }}"
  minio_namespace: "{{ base_image.namespace }}"
  minio_secret_key_key: s3_ldap.passwords

  sleep_factor: {{ tests.pipelines.sleep_factor }}
  user_batch_size: {{ tests.pipelines.user_batch_size }}

  git_pull: null #refs/pull/716/merge

server deploy_minio_s3_server:
  namespace: "{{ base_image.namespace }}"
  secret_properties_file: {{ s3_ldap_password_location }}
  bucket_name: {{ base_image.minio.bucket_name }}
