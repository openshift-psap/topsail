ci_presets:
  # name of the presets to apply, or null if no preset
  name: null
  # list of names of the presets to apply, or a single name, or null if no preset
  names: null

  single:
    clusters.create.type: single

  keep:
    clusters.create.keep: true
    clusters.create.ocp.tags.Project: PSAP/CodeFlare/mcad/home-dev

  light_cluster:
    clusters.create.ocp.deploy_cluster.target: cluster_light

  full_cluster:
    clusters.create.ocp.deploy_cluster.target: cluster

  light:
    extends: [light_cluster]

  metal:
    clusters.sutest.is_metal: true
    clusters.driver.is_metal: true

  not_metal:
    clusters.sutest.is_metal: false
    clusters.driver.is_metal: false

  gpu:
    tests.mcad.want_gpu: true
    tests.mcad.tests_to_run: [gpu_all_schedulable, gpu_scheduling, gpu_unschedulable]

  fill_workernodes:
    clusters.sutest.worker.fill_resources.enabled: true

  cpu_light_unschedulable:
    tests.mcad.tests_to_run: [cpu_light_unschedulable]

  cpu_light_scheduling:
    tests.mcad.tests_to_run: [cpu_light_scheduling]
    tests.mcad.test_templates.cpu_light_scheduling.aw.count: 100

  icelake:
    extends: [metal]

secrets:
  dir:
    name: psap-ods-secret
    env_key: PSAP_ODS_SECRET_PATH
  # name of the file containing the properties of LDAP secrets
  s3_ldap_password_file: s3_ldap.passwords
  keep_cluster_password_file: get_cluster.password
  brew_registry_redhat_io_token_file: brew.registry.redhat.io.token
clusters:
  create:
    type: single # can be: single, ocp, managed
    keep: false
    name_prefix: codeflare-ci
    ocp:
      # list of tags to apply to the machineset when creating the cluster
      tags:
        TicketId: 160
        Project: PSAP/CodeFlare/mcad
      deploy_cluster:
        target: cluster_light
      base_domain: psap.aws.rhperfscale.org
      version: 4.12.12
      region: us-west-2
      control_plane:
        type: m6a.xlarge
      workers:
        type: m6a.2xlarge
        count: 2

  sutest:
    is_metal: false
    lab:
      name: null
    compute:
      machineset:
        name: workload-pods
        type: g4dn.xlarge
        count: 1
    worker:
      label: initial_worker_node=true
      fill_resources:
        enabled: false
        namespace: worker-nodes-placeholder
  driver:
    is_metal: false
    compute:
      dedicated: true
      machineset:
        name: test-pods
        count: null
        taint:
          key: only-test-pods
          value: "yes"
          effect: NoSchedule
  cleanup_on_exit: false
odh:
  namespace: opendatahub
  kfdefs:
  - https://raw.githubusercontent.com/opendatahub-io/odh-manifests/master/kfdef/odh-core.yaml
  - https://raw.githubusercontent.com/opendatahub-io/distributed-workloads/main/codeflare-stack-kfdef.yaml
  operators:
  - name: codeflare-operator
    catalog: community-operators
    namespace: all
  - name: opendatahub-operator
    catalog: community-operators
    namespace: all
gpu:
  time_sharing:
    replicas: 10
tests:
  mcad:
    namespace: mcad-load-test

    dry_mode: false
    visualize: true
    capture_prom: true
    prepare_nodes: true

    want_gpu: false
    tests_to_run: [cpu_light_all_schedulable, cpu_light_scheduling, cpu_light_unschedulable]
    distribution: poisson

    test_templates:
      common_gpu:
        aw:
          job:
            template_name: gpu_burn
          pod:
            count: 1
            runtime: 30
            requests:
              nvidia.com/gpu: 1
        node:
          instance_type: g4dn.xlarge
          wait_gpus: true
        timespan: 0 #minutes, all at once

      common_cpu:
        aw:
          job:
            template_name: sleeper
          pod:
            count: 1
            runtime: 30
            requests:
              cpu: 100m
        node:
          instance_type: m6i.2xlarge
          wait_gpus: false
        timespan: 0 #minutes, all at once

      common_unschedulable:
        aw:
          states:
            target: [Queueing, HeadOfLine, Pending, Failed]
            unexpected: [Dispatched, Running, Completed]
          pod:
            runtime: 300
        node:
          count: 0
          wait_gpus: false

      common_scheduling:
        aw:
          job:
            run_job_mode: true

      gpu_all_schedulable:
        extends: [common_gpu]
        aw:
          count: 10
        node:
          count: 1

      gpu_scheduling:
        extends: [common_gpu, common_scheduling]
        aw:
          count: 20
        node:
          count: 1

      gpu_unschedulable:
        extends: [common_gpu, common_unschedulable]
        aw:
          count: 50

      common_light:
        node:
          count: 0

      cpu_light_all_schedulable:
        extends: [common_cpu, common_light]
        aw:
          count: 10

      cpu_light_scheduling:
        extends: [common_cpu, common_light, common_scheduling]
        aw:
          count: 20

      cpu_light_unschedulable:
        extends: [common_cpu, common_light, common_unschedulable]
        aw:
          count: 200
          pod:
            requests:
              cpu: 150

matbench:
  preset: null
  workload: codeflare
  config_file: plots.yaml
  download:
    mode: prefer_cache
    url:
    url_file:
    # if true, copy the results downloaded by `matbench download` into the artifacts directory
    save_to_artifacts: false
  ignore_exit_code: true
  # directory to plot. Set by testing/common/visualize.py before launching the visualization
  test_directory: null
  generate_lts: false
